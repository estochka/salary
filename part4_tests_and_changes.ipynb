{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb4f2f8",
   "metadata": {},
   "source": [
    "_______________________________________________________\n",
    "# Предсказание зарплаты по данным резюме\n",
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920287f4",
   "metadata": {},
   "source": [
    "## Часть 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7f687",
   "metadata": {},
   "source": [
    "**Загрузка и настройка работы сохраненных моделей**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a09e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1 imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch import nn\n",
    "\n",
    "#create custom pipe\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4d4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2 imports\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from catboost import Pool\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faed53",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83af69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(real, pred):\n",
    "    print(f'MSE = {mean_squared_error(real, pred)}')\n",
    "    print(f'R2 = {r2_score(real, pred)}')\n",
    "    print(f'MAE = {mean_absolute_error(real, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc70ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_transform(data: pd.Series, \n",
    "                   device: torch.device,\n",
    "                   tokenizer: ppb.models,\n",
    "                   model_bert: ppb.models,\n",
    "                   batch_size: int = 0) -> pd.DataFrame:\n",
    "    \n",
    "    if not batch_size:\n",
    "        batch_size = data.shape[0]\n",
    "    \n",
    "    b_token = data.apply((lambda x: tokenizer.encode(x, \n",
    "                                                     add_special_tokens=True,\n",
    "                                                     truncation=True)))\n",
    "    max_len = max(b_token.map(len))\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in b_token.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    embeddings = []\n",
    "    start_ = 0\n",
    "    stop_ = batch_size\n",
    "    for j in range(padded.shape[0] // batch_size):\n",
    "        batch = torch.LongTensor(padded[start_:stop_]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[start_:stop_]) \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "        embeddings.append(batch_embeddings[0][:,0,:])\n",
    "        start_ += batch_size\n",
    "        stop_ += batch_size\n",
    "    bert_features = np.concatenate(embeddings)\n",
    "    return pd.DataFrame(bert_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cddb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(data: pd.DataFrame, nlp: spacy.lang, col: str = 'full_description') -> pd.DataFrame:\n",
    "    #fist clear text part\n",
    "    #http https www\n",
    "    data[col] = data[col].str.replace(r'((https?:\\/\\/)|w{3}).*?( |$)',' ', regex=True)\n",
    "    data[col] = data[col].str.replace(r'[^A-Za-z\\']',' ', regex=True).str.lower().str.strip()\n",
    "    data[col] = data[col].str.replace(r'\\W{2,}',' ', regex=True)\n",
    "\n",
    "    #lemma part\n",
    "    data['clear_text'] = data[col].apply(lambda row: ' '.join([w.lemma_ for w in nlp(row) if not w.is_stop]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbe36e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, \n",
    "                                                    ppb.DistilBertTokenizer, \n",
    "                                                    'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model_bert = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "with open('data/location_dict.pkl', 'rb') as f:\n",
    "    location_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc9b31",
   "metadata": {},
   "source": [
    "Подгрузка заранее оставленных тестовых)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b1b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Train_rev1.csv', index_col=[0])\n",
    "df = df[-2000:].reset_index(drop='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6cdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df[['FullDescription','LocationNormalized','Category']]\n",
    "y_test = df['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63909d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if another name of columns on input :)\n",
    "X_test.columns = ['full_description', 'location_normalized', 'category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e677e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7481/2808529904.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace(r'((https?:\\/\\/)|w{3}).*?( |$)',' ', regex=True)\n",
      "/tmp/ipykernel_7481/2808529904.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace(r'[^A-Za-z\\']',' ', regex=True).str.lower().str.strip()\n",
      "/tmp/ipykernel_7481/2808529904.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace(r'\\W{2,}',' ', regex=True)\n",
      "/tmp/ipykernel_7481/2808529904.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['clear_text'] = data[col].apply(lambda row: ' '.join([w.lemma_ for w in nlp(row) if not w.is_stop]))\n"
     ]
    }
   ],
   "source": [
    "temps = text_transform(X_test, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5230b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = text_transform(X_test, nlp)\n",
    "cat_test = temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076d8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['full_description', 'location_normalized', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ae172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fd0ed11a200>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor()\n",
    "cat_model.load_model('models/full_catboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87c45244",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X_test[cat_features].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ada3bc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304699179320459"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.score(Pool(cat_test[cat_features], \n",
    "                     y_test, \n",
    "                     cat_features=cat_features, \n",
    "                     text_features=['full_description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "750fd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat_model.predict(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2370fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 37347248.10111603\n",
      "R2 = 0.7781866173245335\n",
      "MAE = 3986.1446843133504\n"
     ]
    }
   ],
   "source": [
    "metrics(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f7f7a",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "25790f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Что-то мне в процессе не понравилось делать отдельный шаг для трансформации категорий, без пайплайна\n",
    "# ААААА ЗАЧЕМ Я СЮДА ПОЛЕЗЛА, А?!?!?! Ну теперь принцип знаю, хоть и основы.\n",
    "# Кривой новый класс для пайплайна. Работает даже. \n",
    "# Результаты старой версии и новой сравнила.\n",
    "\n",
    "class location_category(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, location_dict):\n",
    "        #load dict\n",
    "        self.location_dict = location_dict\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        #no need to fit, only transform\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X.apply(lambda x: location_dict.get(x,'few')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "2216799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dict\n",
    "with open('data/location_dict.pkl', 'rb') as f:\n",
    "    location_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "949f85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "])\n",
    "\n",
    "location_transform = ColumnTransformer([('loc', location_category(location_dict), 'location_normalized')], \n",
    "                                       remainder='passthrough')\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('loc', location_transform),\n",
    "    ('prep', cat_pipe)\n",
    "   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "76422bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_pipe = final_pipe.fit(df_pipe)\n",
    "with open(\"models/learned_pipe_test.pkl\", \"wb\") as f:\n",
    "        pickle.dump(learned_pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "23a905aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   18   19   20   21  \\\n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    22   23   24   25   26   27  \n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "5  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "6  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "7  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "8  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "9  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(learned_pipe.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfeab11",
   "metadata": {},
   "source": [
    "Нейро не протестить на локальном нормально. Но там в колабе сойдет."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
